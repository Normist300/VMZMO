{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f8c5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вариант: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Вариант:\", sum([ord(x) for x in u'Седых']) % 3 + 1)\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c1c5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_1:\n",
    "    def __init__(self, a_min, a_max, b_min, b_max, p1, p2, p3, limit=False):\n",
    "        self.a_min = a_min\n",
    "        self.a_max = a_max\n",
    "        self.b_min = b_min\n",
    "        self.b_max = b_max\n",
    "        self.p1 = p1\n",
    "        self.p2 = p2\n",
    "        self.p3 = p3\n",
    "        self.limit = limit\n",
    "\n",
    "    def sample_a(self):\n",
    "        return np.random.uniform(self.a_min, self.a_max)\n",
    "\n",
    "    def sample_b(self):\n",
    "        return np.random.uniform(self.b_min, self.b_max)\n",
    "\n",
    "    def sample_c(self, a, b):\n",
    "        c_a = np.random.binomial(a, self.p1)\n",
    "        c_b = np.random.binomial(b, self.p2)\n",
    "        c = c_a + c_b\n",
    "        if self.limit:\n",
    "            c = np.clip(c, 0, self.a_max + self.b_max)\n",
    "        return c\n",
    "\n",
    "    def sample_d(self, c):\n",
    "        c = max(c, 1e-8)  # Минимальное значение для c, чтобы избежать ошибок\n",
    "        din_sample = np.random.negative_binomial(c, self.p3)\n",
    "        d = c + din_sample\n",
    "        if self.limit:\n",
    "            d = np.clip(d, 0, 2 * (self.a_max + self.b_max))\n",
    "        return d\n",
    "\n",
    "    def joint_probability(self):\n",
    "        a = self.sample_a()\n",
    "        b = self.sample_b()\n",
    "        c = self.sample_c(a, b)\n",
    "        d = self.sample_d(c)\n",
    "        return a, b, c, d\n",
    "\n",
    "    def generate_samples(self, n_samples):\n",
    "        samples = [self.joint_probability() for _ in range(n_samples)]\n",
    "        return pd.DataFrame(samples, columns=['a', 'b', 'c', 'd'])\n",
    "\n",
    "\n",
    "class Model_2(Model_1):\n",
    "    def sample_c(self, a, b):\n",
    "        mean = a * self.p1 + b * self.p2\n",
    "        c = np.random.poisson(mean)\n",
    "        if self.limit:\n",
    "            c = np.clip(c, 0, self.a_max + self.b_max)\n",
    "        return c\n",
    "\n",
    "    def sample_d(self, c):\n",
    "        c = max(c, 1e-8)  # Минимальное значение для c, чтобы избежать ошибок\n",
    "        bin_sample = np.random.binomial(c, self.p3)\n",
    "        d = c + bin_sample\n",
    "        if self.limit:\n",
    "            d = np.clip(d, 0, 2 * (self.a_max + self.b_max))\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ff87c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_min = 75\n",
    "a_max = 90\n",
    "b_min = 500\n",
    "b_max = 600\n",
    "p1 = 0.1\n",
    "p2 = 0.01\n",
    "p3 = 0.3\n",
    "\n",
    "model_1 = Model_1(a_min = a_min, a_max = a_max, b_min = b_min, b_max = b_max, p1 = p1, p2 = p2, p3 = p3, limit = True)\n",
    "samples_model_1 = model_1.generate_samples(1000)\n",
    "stats_model_1 = samples_model_1.describe().loc[['mean', 'std']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b76e708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'stats_model_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel 1: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 1. Вычисление мат. ожиданий для a и b\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m mean_a \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(stats_model_1\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      5\u001b[0m mean_b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(stats_model_1\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# 2. Функция для вычисления c в зависимости от a и b\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stats_model_1' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Model 1: \")\n",
    "\n",
    "# 1. Вычисление мат. ожиданий для a и b\n",
    "mean_a = round(stats_model_1.loc['mean', 'a'])\n",
    "mean_b = round(stats_model_1.loc['mean', 'b'])\n",
    "\n",
    "# 2. Функция для вычисления c в зависимости от a и b\n",
    "def calculate_c(a, b, p1, p2):\n",
    "    c_a = np.random.binomial(a, p1, size=1000)  # Генерация выборки для c|a\n",
    "    c_b = np.random.binomial(b, p2, size=1000)  # Генерация выборки для c|b\n",
    "    return c_a, c_b\n",
    "\n",
    "# 3. Поиск множества точек (p1, p2), при которых D[c|b] < D[c|a]\n",
    "p1_values = np.linspace(0.01, 0.5, 50)\n",
    "p2_values = np.linspace(0.01, 0.5, 50)\n",
    "\n",
    "points_D_cb_less_D_ca = []\n",
    "points_D_cb_greater_D_ca = []\n",
    "\n",
    "for p1 in p1_values:\n",
    "    for p2 in p2_values:\n",
    "        c_a_samples, c_b_samples = calculate_c(mean_a, mean_b, p1, p2)\n",
    "\n",
    "        D_ca = np.var(c_a_samples)  # Дисперсия c|a\n",
    "        D_cb = np.var(c_b_samples)  # Дисперсия c|b\n",
    "\n",
    "        if D_cb < D_ca:\n",
    "            points_D_cb_less_D_ca.append((p1, p2))\n",
    "        else:\n",
    "            points_D_cb_greater_D_ca.append((p1, p2))\n",
    "\n",
    "# 4. Преобразуем найденные точки в массивы для удобства визуализации\n",
    "points_D_cb_less_D_ca = np.array(points_D_cb_less_D_ca)\n",
    "points_D_cb_greater_D_ca = np.array(points_D_cb_greater_D_ca)\n",
    "\n",
    "# 5. Построение графика множества точек (p1, p2)\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Множество точек, где D[c|b] < D[c|a]\n",
    "plt.scatter(points_D_cb_less_D_ca[:, 0], points_D_cb_less_D_ca[:, 1], color='green', label='D[c|b] < D[c|a]')\n",
    "\n",
    "# Множество точек, где D[c|b] > D[c|a]\n",
    "plt.scatter(points_D_cb_greater_D_ca[:, 0], points_D_cb_greater_D_ca[:, 1], color='red', label='D[c|b] > D[c|a]')\n",
    "\n",
    "# Настройка графика\n",
    "plt.title('Model 1 Множества точек (p1, p2)')\n",
    "plt.xlabel('p1')\n",
    "plt.ylabel('p2')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 6. Проверка линейной разделимости множеств\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Создадим набор данных для классификации\n",
    "X = np.vstack((points_D_cb_less_D_ca, points_D_cb_greater_D_ca))\n",
    "y = np.hstack((np.zeros(len(points_D_cb_less_D_ca)), np.ones(len(points_D_cb_greater_D_ca))))\n",
    "\n",
    "# Обучим линейный классификатор\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Проверим точность разделения\n",
    "print(f\"Линейная разделимость: { clf.score(X, y) } - \", clf.score(X, y) > 0.95)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\\n\\nModel 2: \")\n",
    "# 1. Вычисление мат. ожиданий для a и b\n",
    "mean_a = round(stats_model_2.loc['mean', 'a'])\n",
    "mean_b = round(stats_model_2.loc['mean', 'b'])\n",
    "\n",
    "# 2. Функция для вычисления c в зависимости от a и b\n",
    "def calculate_c(a, b, p1, p2):\n",
    "    c_a = np.random.binomial(a, p1, size=1000)  # Генерация выборки для c|a\n",
    "    c_b = np.random.binomial(b, p2, size=1000)  # Генерация выборки для c|b\n",
    "    return c_a, c_b\n",
    "\n",
    "# 3. Поиск множества точек (p1, p2), при которых D[c|b] < D[c|a]\n",
    "p1_values = np.linspace(0.01, 0.5, 50)\n",
    "p2_values = np.linspace(0.01, 0.5, 50)\n",
    "\n",
    "points_D_cb_less_D_ca = []\n",
    "points_D_cb_greater_D_ca = []\n",
    "\n",
    "for p1 in p1_values:\n",
    "    for p2 in p2_values:\n",
    "        c_a_samples, c_b_samples = calculate_c(mean_a, mean_b, p1, p2)\n",
    "\n",
    "        D_ca = np.var(c_a_samples)  # Дисперсия c|a\n",
    "        D_cb = np.var(c_b_samples)  # Дисперсия c|b\n",
    "\n",
    "        if D_cb < D_ca:\n",
    "            points_D_cb_less_D_ca.append((p1, p2))\n",
    "        else:\n",
    "            points_D_cb_greater_D_ca.append((p1, p2))\n",
    "\n",
    "# 4. Преобразуем найденные точки в массивы для удобства визуализации\n",
    "points_D_cb_less_D_ca = np.array(points_D_cb_less_D_ca)\n",
    "points_D_cb_greater_D_ca = np.array(points_D_cb_greater_D_ca)\n",
    "\n",
    "# 5. Построение графика множества точек (p1, p2)\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Множество точек, где D[c|b] < D[c|a]\n",
    "plt.scatter(points_D_cb_less_D_ca[:, 0], points_D_cb_less_D_ca[:, 1], color='green', label='D[c|b] < D[c|a]')\n",
    "\n",
    "# Множество точек, где D[c|b] > D[c|a]\n",
    "plt.scatter(points_D_cb_greater_D_ca[:, 0], points_D_cb_greater_D_ca[:, 1], color='red', label='D[c|b] > D[c|a]')\n",
    "\n",
    "# Настройка графика\n",
    "plt.title('Model 2 Множества точек (p1, p2)')\n",
    "plt.xlabel('p1')\n",
    "plt.ylabel('p2')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 6. Проверка линейной разделимости множеств\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Создадим набор данных для классификации\n",
    "X = np.vstack((points_D_cb_less_D_ca, points_D_cb_greater_D_ca))\n",
    "y = np.hstack((np.zeros(len(points_D_cb_less_D_ca)), np.ones(len(points_D_cb_greater_D_ca))))\n",
    "\n",
    "# Обучим линейный классификатор\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Проверим точность разделения\n",
    "print(f\"Линейная разделимость: { clf.score(X, y) } - \", clf.score(X, y) > 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bb21a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ad9713",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
